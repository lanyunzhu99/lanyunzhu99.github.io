<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv='content-language' content='en-gb'>
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Lanyun's Homepage</title>
<style>
  .lighter-text {
      opacity: 0.5; /* 设置字体的透明度，值为 0.0（完全透明）到 1.0（完全不透明）之间 */
  }
</style>
<meta name="google-site-verification" content="loaFQ6oWlZ1NZ4wxTUNrFzjSMrNeTcOtZnV5Z7P6D9o" />
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<div id="toptitle">
</div>
<table class="imgtable"><tr><td>
<img src="photo2.jpg" alt="alt text" width="140.8px" height="187.66px" /></a>&nbsp;</td>
<td align="left"><p></p><font size="6">  Lanyun Zhu 祝澜耘 </font><br />
<br />
<br />
Ph.D. Student <br />
Singapore University of Technology and Design (SUTD)<br />
<br />
Email: <a href="lanyun_zhu@mymail.sutd.edu.sg">lanyun_zhu@mymail.sutd.edu.sg</a></p>
<a href="CV_Lanyun.pdf" title="[Lanyun_Resume]" target="top">CV</a> / <a href="https://scholar.google.com/citations?user=urOSnlQAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a></p>

</td></tr></table>
<p class="lighter-text">Note: I am NOT the cat in the photo, but the person behind the cat.</p>
<h2>About Me</h2>
I'm a PhD student in Singapore University of Technology and Design (SUTD) from 2021, advised by <a href="https://people.sutd.edu.sg/~jun_liu/">Prof. Jun Liu</a>. I'm also a technical consultant for the startup <a href="http://www.kokoni.ltd/">Motion Tech</a>. Before that, I got the bachelor’s degree in June, 2020 from Beihang University. I also spent some wonderful times in Megvii, Sensetime and Johns Hopkins University. Currently, I am honourably sponsored by <a href="https://aisingapore.org/research/phd-fellowship-programme/">AISG PhD Fellowship Programme</a> (one of the top Singapore scholarships). I work closely with NVIDIA and Alibaba Group. </p>

My research direction is computer vision. At present, most of my works are focused on image segmentation, source-effecient learning, and large vision-language models. I’m also committed to the industrial applications of computer vision technology. </p>

I am always open to research collaborations. Please feel free to drop me an email if you are interested.
</li>
</ul>
<h2>Resume</h2>
<a href="CV_Lanyun.pdf" title="[Lanyun_Resume]" target="top">[English Resume]</a>  <a href="CV_Lanyun_CN.pdf" title="[Lanyun_Resume]" target="top">[中文简历]</a>
</li>
</ul>
<h2>News</h2>

<font color = 'blue'> (Feb 2024) We are organizing <a href="https://sutdcv.github.io/MMVRAC/">The 2nd Multi-Modal Video Reasoning and Analyzing Competition</a> at ICME24 ! </font></p>
<font color = 'red'> (Jul 2023) One paper accepted to ICCV 2023 ! </font></p>
<font color = 'blue'> (Apr 2023) We release the <a href="https://tianrun-chen.github.io/SAM-Adaptor/static/pdfs/Adaptor.pdf">paper</a> and <a href="https://github.com/tianrun-chen/SAM-Adaptor-PyTorch">code</a> for SAM-Adapter, a pioneering attempt to finetune SAM ! </font></p>
<font color = 'red'> (Mar 2023) One paper accepted to CVPR 2023 ! </font></p>
<font color = 'red'> (Mar 2021) One paper accepted to CVPR 2021 ! </font></p>
</li>
</ul>
<h2>Selected Publications </h2>
<b>Conference Papers</b></p>
<ol>
  <li><p><b>[CVPR2024]</b><b> Lanyun Zhu</b>, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu, LLaFS: When Large-Language Models Meet Few-Shot Segmentation, <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2024 </p>
</li>
  <li><p><b>[CVPR2024]</b><b> Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu, Addressing Background Context Bias in Few-Shot Segmentation through Iterative Modulation, <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2024 </p>
</li>
  <li><p><b>[ICCV2023]</b><b> Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu, Learning Gabor Texture Features for Fine-Grained Recognition, <i>International Conference on Computer Vision (ICCV)</i> 2023 <a href="https://arxiv.org/pdf/2308.05396.pdf">[paper]</a></p>
</li>
  <li><p><b>[CVPR2023]</b><b> Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu, Continual Semantic Segmentation with Automatic Memory Sample Selection, <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2023 <a href="https://arxiv.org/pdf/2304.05015.pdf">[paper]</a></p> 
</li>
  <li><p><b>[CVPR2021]</b><b> Lanyun Zhu</b>, Deyi Ji, Shiping Zhu, Weihao Gan, Wei Wu, Junjie Yan, Learning Statistical Texture for Semantic Segmentation, <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2021 <a href="https://arxiv.org/pdf/2103.04133.pdf">[paper]</a></p>
</li>
  <li><p><b>[ICCV2023 Workshop]</b> Tianrun Chen*, <b>Lanyun Zhu*</b>, Chaotao Ding, Runlong Cao, Shangzhan Zhang, Yan Wang, Zejian Li, Lingyun Sun, Papa Mao, Ying Zang, SAM-Adapter: Adapting Segment Anything in Underperformed Scenes, <i>ICCV2023 1st Workshop on Visual Continual Learning</i> <a href="https://tianrun-chen.github.io/SAM-Adaptor/static/pdfs/Adaptor.pdf">[paper]</a> <a href="https://github.com/tianrun-chen/SAM-Adaptor-PyTorch">[code]</a> <font color = 'red'>(Github 730 Stars)</font></a></p>
</li>
  <li><p><b>[3DV2022]</b> Xiao Fu, Shangzhan Zhang, Tianrun Chen, Yichong Lu, <b>Lanyun Zhu</b>, Xiaowei Zhou, Andreas Geiger, Yiyi Liao., Panoptic NeRF: 3D-to-2D Label Transfer for Panoptic Urban Scene Segmentation, <i>International Conference on 3D Vision (3DV) </i>2021 <a href="https://arxiv.org/pdf/2203.15224.pdf">[paper]</a></p>
</li>
</ol>

<b>Journal Papers</b></p>
<ol>
  <li><p><b>[TMM]</b> Tianrun Chen, Chaotao Ding, <b>Lanyun Zhu</b>, Ying Zang, Yiyi Liao, Zejian Li, and Lingyun Su, Reality3DSketch: Rapid 3D Modeling of Objects from Single Free-hand Sketches, <i> IEEE Transactions on Multimedia</i></a></p>
  </li>
  <li><p><b>[TMI]</b> Yan Wang, Jian Cheng, Yixin Chen, Shuai Shao, <b>Lanyun Zhu</b>, Zhenzhou Wu, Tao Liu, Haogang Zhu, FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation,<i> IEEE Transactions on Medical Imaging</i> <a href="https://arxiv.org/pdf/2304.13672.pdf">[paper]</a></p>
</li>
</ol>
<b>Preprint Papers</b></p>
<ol>
  <li><b>Lanyun Zhu</b>, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu, LLaFS: When Large-Language Models Meet Few-Shot Segmentation, <i>Arxiv Preprint</i> <a href="https://arxiv.org/pdf/2311.16926.pdf">[paper]</a></p>
</ol>
<p><b>Note</b>: * indicates equal contribution.</p>
<p><a href="https://scholar.google.com/citations?user=urOSnlQAAAAJ&hl=zh-CN&oi=ao">Full list of publications in Google Scholar</a>.</p>
<h2>Experiences</h2>
<ol>
  <li>Research Intern | CCVL Lab, Johns Hopkins University| Apr 2020 - Sep 2021</p>
    Mentor: <a href="https://yingwei.li/">Dr. Yingwei Li</a> | <a href="http://www.cs.jhu.edu/~ayuille/">Leader: Prof.Alan Yuille</a></p>
  </li>
  <li>Research Intern | Sensetime, Beijing, China | June 2020 - July 2021</p>
    Mentor: <a href="https://jankyee.github.io">Mr. Deyi Ji</a> |  Mr. Wei Wu</p>
  </li>
  <li>Research Intern | Megvii, Beijing, China | Sep. 2019 - May 2020</p>
    Mentor: Dr. Zhikang Liu | Leader: Dr. Chi Zhang</p>
  </li>
</ol>
<h2>Service</h2>
<li><b>Conference Reviewer</b>: CVPR, ICML, NeurIPS, ICLR, ECCV, ACM MM
</li>
<li><b>Journal Reviewer</b>: IJCV, IEEE TIP, IEEE TCSVT, IEEE TII, IEEE TIM
</li>
<li><b>Co-Organizor</b>:  ICME2024 Grand Challenge – <a href="https://sutdcv.github.io/MMVRAC/">The 2nd Multi-Modal Video Reasoning and Analyzing Competition</a>
</li>
</td>
</tr>
</table>
</body>
</html>
