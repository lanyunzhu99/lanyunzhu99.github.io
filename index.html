<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv='content-language' content='en-gb'>
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Lanyun's Homepage</title>
<style>
  .lighter-text {
      opacity: 0.5; /* 设置字体的透明度，值为 0.0（完全透明）到 1.0（完全不透明）之间 */
  }
</style>
<meta name="google-site-verification" content="loaFQ6oWlZ1NZ4wxTUNrFzjSMrNeTcOtZnV5Z7P6D9o" />
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<div id="toptitle">
</div>
<table class="imgtable"><tr><td>
<img src="photo2.jpg" alt="alt text" width="140.8px" height="187.66px" /></a>&nbsp;</td>
<td align="left"><p></p><font size="6">  Lanyun Zhu 祝澜耘 </font><br />
<br />
<br />
Postdoctoral Fellow <br />
<br />
Email: <a href="lanyun_zhu@mymail.sutd.edu.sg">lanyun_zhu@mymail.sutd.edu.sg</a></p>
<a href="CV_Lanyun.pdf" title="[Lanyun_Resume]" target="top">CV</a> / <a href="https://scholar.google.com/citations?user=urOSnlQAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a></p>



</td></tr></table>

<h2>About Me</h2>
I am currently a postdoctoral researcher. Prior to this, I obtained my Ph.D. from the Singapore University of Technology and Design (SUTD), under the supervision of <a href="https://sites.google.com/view/junliu021">Professor Jun Liu</a> and <a href="https://istd.sutd.edu.sg/people/faculty/soh-de-wen">Professor Soh De Wen</a>. I received my bachelor’s degree from Beihang University in June 2020.  I also spent some wonderful times in Megvii and SenseTime. Currently, I work closely with NVIDIA, Alibaba (<a href="https://scholar.google.com/citations?user=T9AzhwcAAAAJ&hl=en&oi=ao">Professor Jieping Ye</a>), and Tencent.</p>

My research directions are multimodal learning and computer vision. Currently, most of my works are focused multimodal large language models (MLLMs) and image segmentation. My research goal is to build <b>efficient, trustworthy, and fine-grained multimodal systems </b> that can process or integrate information from diverse modalities—such as text, images, videos, and data from other sensors—to effectively address a wide range of real-world industrial and scientific challenges. I believe that a practical multimodal system should be <b>cheap</b>—with lower training and deployment costs; <b>powerful</b>—with more comprehensive and fine-grained capabilities; and <b>reliable</b>—with stronger robustness and minimal instability. Currently, I am exploring new techniques to achieve these goals within MLLMs and to advance their applications in real-world industrial scenarios, such as online content safety, as well as in scientific domains such as healthcare and agriculture.</p>

I am always open to research collaborations. Please feel free to drop me an email if you are interested.



</li>
</ul>

<h2>Resume</h2>
<a href="CV_Lanyun.pdf" title="[Lanyun_Resume]" target="top">[English Resume]</a>  <a href="CV_Lanyun_CN.pdf" title="[Lanyun_Resume]" target="top">[中文简历]</a>
</li>
</ul>


<h2>Selected Publications </h2>
* refers to equal contribution; # refers to corresponding author</p>
<b>Conference Papers</b></p>

<ol>
  <li><p><b>[ICML2025]</b> <b> Lanyun Zhu</b>, Deyi Ji, Tianrun Chen, Haiyang Wu, De Wen Soh, Jun Liu, CPCF: A Cross-Prompt Contrastive Framework for Referring Multimodal Large Language Models, <i> International Conference on Machine Learning (ICML)</i> 2025<font color = 'red'> </font> </p>
</li> 
  <li><p><b>[ICML2025]</b> Qianxiong Xu, <b>Lanyun Zhu</b>, Xuanyi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao, Unlocking the Power of SAM 2 for Few-Shot Segmentation, <i> International Conference on Machine Learning (ICML)</i> 2025<font color = 'red'> </font> </p>
</li> 
  <li><p><b>[CVPR2025]</b> <b> Lanyun Zhu</b>, Tianrun Chen, Qianxiong Xu, Xuanyi Liu, Deyi Ji, Haiyang Wu, De Wen Soh, Jun Liu, POPEN: Preference-Based Optimization and Ensemble for LVLM-Based Reasoning Segmentation, <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2025<font color = 'red'> </font> </p>
</li> 
  <li><p><b>[ACL2025 Industry Track]</b> Deyi Ji, Yuekui Yang, Haiyang Wu, Shaoping Ma, Tianrun Chen, <b>Lanyun Zhu#</b>, RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning, <i> Annual Meeting of the Association for Computational Linguistics (ACL)</i> 2025 (oral)<font color = 'red'> </font> </p>
</li> 
  <li><p><b>[NeurIPS2024]</b> Qianxiong Xu, Xuanyi Liu, </b><b> Lanyun Zhu</b>, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao, Hybrid Mamba for Few-Shot Segmentation, <i> Annual Conference on Neural Information Processing Systems (NeurIPS)</i> 2024<font color = 'red'> </font> </p>
</li>
  <li><p><b>[ICML2024]</b> Deyi Ji, Feng Zhao, </b><b> Lanyun Zhu</b>, Wenwei Jin, Hongtao Lu, Jieping Ye, Discrete Latent Perspective Learning for Segmentation and Detection, <i> International Conference on Machine Learning (ICML)</i> 2024 (spotlight) </p>
</li>
  <li><p><b>[CVPR2024]</b><b> Lanyun Zhu</b>, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu, LLaFS: When Large Language Models Meet Few-Shot Segmentation, <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2024 </p>
</li>
  <li><p><b>[CVPR2024]</b><b> Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu, Addressing Background Context Bias in Few-Shot Segmentation through Iterative Modulation, <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2024 </p>
</li>
  <li><p><b>[ICCV2023]</b><b> Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, Jun Liu, Learning Gabor Texture Features for Fine-Grained Recognition, <i>International Conference on Computer Vision (ICCV)</i> 2023 </p>
</li>
  <li><p><b>[CVPR2023]</b><b> Lanyun Zhu</b>*, Tianrun Chen*, Jianxiong Yin, Simon See, Jun Liu, Continual Semantic Segmentation with Automatic Memory Sample Selection, <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2023 </p> 
</li>
  <li><p><b>[CVPR2021]</b><b> Lanyun Zhu</b>*, Deyi Ji*, Shiping Zhu, Weihao Gan, Wei Wu, Junjie Yan, Learning Statistical Texture for Semantic Segmentation, <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 2021 </p>
</li>
  <li><p><b>[ICCV2023 Workshop]</b> Tianrun Chen*, <b>Lanyun Zhu*</b>, Chaotao Ding, Runlong Cao, Shangzhan Zhang, Yan Wang, Zejian Li, Lingyun Sun, Papa Mao, Ying Zang, SAM-Adapter: Adapting Segment Anything in Underperformed Scenes, <i>ICCV2023 1st Workshop on Visual Continual Learning</i> </p>
</li>
  <li><p><b>[3DV2022]</b> Xiao Fu, Shangzhan Zhang, Tianrun Chen, Yichong Lu, <b>Lanyun Zhu</b>, Xiaowei Zhou, Andreas Geiger, Yiyi Liao., Panoptic NeRF: 3D-to-2D Label Transfer for Panoptic Urban Scene Segmentation, <i>International Conference on 3D Vision (3DV) </i>2021 </p>
</li>
</ol>

<b>Journal Papers</b></p>
<ol>
  <li><p><b>[TPAMI]</b> <b>Lanyun Zhu</b>, Tianrun Chen, Deyi Ji, Peng Xu, Jieping Ye, Jun Liu, LLaFS++: Few-Shot Image Segmentation With Large Language Models, <i> IEEE Transactions on Pattern Analysis and Machine Intelligence</i></a></p>
  </li>
  <li><p><b>[TPAMI]</b> <b>Lanyun Zhu</b>, Tianrun Chen, Jianxiong Yin, Simon See, De Wen Soh, Jun Liu, Replay Master: Automatic Sample Selection and Effective Memory Utilization for Continual Semantic Segmentation, <i> IEEE Transactions on Pattern Analysis and Machine Intelligence</i></a></p>
  </li>
  <li><p><b>[TIP]</b> <b>Lanyun Zhu</b>, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu, Not Every Patch is Needed: Towards a More Efficient and Effective Backbone for Video-based Person Re-identification, <i> IEEE Transactions on Image Processing</i></a></p>
  </li>
  <li><p><b>[TVCG]</b> Ying Zang, Yuanqi Hu, Xinyu Chen, Yuxia Xu, Suhui Wang, Chunan Yu, <b>Lanyun Zhu</b>, Deyi Ji, Xin Xu, Tianrun Chen, From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching, <i> IEEE Transactions on Visualization and Computer Graphics</i></a></p>
  </li>
  <li><p><b>[TMM]</b> Ying Zang, Runlong Cao, Jianqi Zhang, Yidong Han, Ziyu Cao, Wenjun Hu, Didi Zhu, Zejian Li, <b>Lanyun Zhu</b>, Deyi Ji, Tianrun Chen, Let human sketches help: Empowering challenging image segmentation task with freehand sketches, <i> IEEE Transactions on Multimedia</i></a></p>
  </li>
  <li><p><b>[TMM]</b> Tianrun Chen, Chaotao Ding, <b>Lanyun Zhu</b>, Ying Zang, Yiyi Liao, Zejian Li, and Lingyun Su, Reality3DSketch: Rapid 3D Modeling of Objects from Single Free-hand Sketches, <i> IEEE Transactions on Multimedia</i></a></p>
  </li>
  <li><p><b>[TII]</b> Tianrun Chen, Chunan Yu, Yuanqi Hu, Jing Li, Tao Xu, Runlong Cao, <b>Lanyun Zhu</b>, Ying Zang, Yong Zhang, Zejian Li, Linyun Sun, Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry, <i> IEEE Transactions on Industrial Informatics</i></a></p>
  </li>
  <li><p><b>[TMI]</b> Yan Wang, Jian Cheng, Yixin Chen, Shuai Shao, <b>Lanyun Zhu</b>, Zhenzhou Wu, Tao Liu, Haogang Zhu, FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation,<i> IEEE Transactions on Medical Imaging</i> </p>
</li>
</ol>

<b>PhD Thesis</b></p>
<ol>
  <li><p><b>Lanyun Zhu</b>, Towards Data Efficient and Continual Semantic Segmentation. <a href="lanyun_thesis.pdf" title="Thesis" target="top">[Thesis]</a>
</li>
</ol>

<p><b>Note</b>: * indicates equal contribution.</p>
<p><a href="https://scholar.google.com/citations?user=urOSnlQAAAAJ&hl=zh-CN&oi=ao">Full list of publications in Google Scholar</a>.</p>
<h2>Experiences</h2>
<ol>
  <li>Research Intern | CCVL Lab, Johns Hopkins University| Apr 2020 - Sep 2021</p>
     Supervisor: Prof.Alan Yuille</a></p>
  </li>
  <li>Research Intern | Sensetime, Beijing, China | June 2020 - July 2021</p>
    Mentor: <a href="https://jankyee.github.io">Dr. Deyi Ji</a> |  Mr. Wei Wu</p>
  </li>
  <li>Research Intern | Megvii, Beijing, China | Sep. 2019 - May 2020</p>
    Mentor: Dr. Zhikang Liu | Leader: Dr. Chi Zhang</p>
  </li>
</ol>
<h2>Service</h2>

<li><b>Jounral Associate Editor (AE)</b>: The Visual Computer (2025-)
</li>
<li><b>Conference Reviewer</b>: CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, AAAI, ACM MM
</li>
<li><b>Journal Reviewer</b>: TPAMI, IJCV, TIP, TMM, TCSVT, TII, TIM, PR
</li>
<li><b>Organizor</b>:  ICME2024 Grand Challenge – <a href="https://sutdcv.github.io/MMVRAC/">The 2nd Multi-Modal Video Reasoning and Analyzing Competition</a>
</li>
</td>
</tr>
</table>

<base href="/POPEN/">

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=202&t=n&d=1E1IMMN7nbrANFcSIdC3xhusRJ387BFg6hul_lsdQ_E&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>
</body>
</html>
